{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import dataset_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import similarity\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT=\"../../sabana/dataset/asap-dataset\"\n",
    "# DATASET_ROOT=\"../../sabana/dataset/newbie-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICE_DURATION = 5 # sec\n",
    "EXPANSION_RATE = 2.5\n",
    "FRAME_PER_SECOND = 20 # Hz\n",
    "NUM_SAMPLES = 100\n",
    "QUEUE_SIZE = 8\n",
    "SETTLING_FRAME = 8\n",
    "COMPENSATION_FRAME = 0\n",
    "USE_SUBSEQUENCE_DTW = False\n",
    "\n",
    "SAVE_ROOT = pathlib.Path(\"./save\")\n",
    "\n",
    "if not SAVE_ROOT.exists():\n",
    "    SAVE_ROOT.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = dataset_loader.spawn(dataset_root=DATASET_ROOT, \n",
    "                           slice_duration=SLICE_DURATION,\n",
    "                           expansion_rate=EXPANSION_RATE,\n",
    "                           frame_per_second=FRAME_PER_SECOND,\n",
    "                           shuffle=True)\n",
    "\n",
    "# pos/neg-similarities: [euclidean_similarty, timewarping_similarity, length_ratio]\n",
    "pos_similarities: List[Tuple[float, float, float]] = []\n",
    "neg_similarities: List[Tuple[float, float, float]] = []\n",
    "\n",
    "prev_perfs: List[np.ndarray] = [None] * QUEUE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_ROOT / \"pos.csv\", \"w\", encoding=\"utf-8\") as f1, \\\n",
    "     open(SAVE_ROOT / \"neg.csv\", \"w\", encoding=\"utf-8\") as f2:\n",
    "    pos_csvfile = csv.writer(f1, delimiter=\",\", quotechar=\"|\")\n",
    "    pos_csvfile.writerow([\"Euclidean Similarity\", \"Timewarping Similarity\", \"Length ratio\"])\n",
    "\n",
    "    neg_csvfile = csv.writer(f2, delimiter=\",\", quotechar=\"|\")\n",
    "    neg_csvfile.writerow([\"Euclidean Similarity\", \"Timewarping Similarity\", \"Length ratio\"])\n",
    "\n",
    "    for idx in tqdm(range(NUM_SAMPLES)):\n",
    "        score, perf, _ = next(gen)\n",
    "        score_len = score.shape[-1]\n",
    "        perf_len = perf.shape[-1]\n",
    "\n",
    "        pos_euclidean_similarity, pos_timewarping_similarity, _ = similarity.score(score, perf,\n",
    "                                                                                   settling_frame=SETTLING_FRAME,\n",
    "                                                                                   compensation_frame=COMPENSATION_FRAME,\n",
    "                                                                                   use_subsequence_dtw=USE_SUBSEQUENCE_DTW)\n",
    "        pos_length_ratio = perf_len / (score_len + 1e-7)\n",
    "\n",
    "        pos_csvfile.writerow([pos_euclidean_similarity, pos_timewarping_similarity, pos_length_ratio])\n",
    "        pos_similarities.append((pos_euclidean_similarity, pos_timewarping_similarity, pos_length_ratio))\n",
    "        \n",
    "        if isinstance(prev_perfs[0], np.ndarray):\n",
    "            prev_perf = prev_perfs[0]\n",
    "            prev_perf_len = prev_perf.shape[-1]\n",
    "            neg_euclidean_similarity, neg_timewarping_similarity, _ = similarity.score(score, prev_perf,\n",
    "                                                                                       settling_frame=SETTLING_FRAME,\n",
    "                                                                                       compensation_frame=COMPENSATION_FRAME,\n",
    "                                                                                       use_subsequence_dtw=USE_SUBSEQUENCE_DTW)\n",
    "            neg_length_ratio = prev_perf_len / (score_len + 1e-7)\n",
    "            \n",
    "            neg_csvfile.writerow([neg_euclidean_similarity, neg_timewarping_similarity, neg_length_ratio])\n",
    "            neg_similarities.append((neg_euclidean_similarity, neg_timewarping_similarity, neg_length_ratio))\n",
    "        prev_perfs.pop(0)\n",
    "        prev_perfs.append(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_similarities = np.array(pos_similarities)\n",
    "neg_similarities = np.array(neg_similarities)\n",
    "print(pos_similarities.shape)\n",
    "print(neg_similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_title(f\"expansion rate: {EXPANSION_RATE}, settling frame: {SETTLING_FRAME}\")\n",
    "ax.set_xlabel(\"Euclidean Similarity\")\n",
    "ax.set_ylabel(\"Timewarping Similarity\")\n",
    "ax.scatter(pos_similarities[:, 0], pos_similarities[:, 1], c=\"k\", label=\"Positive\")\n",
    "ax.scatter(neg_similarities[:, 0], neg_similarities[:, 1], c=\"w\", edgecolors=\"k\", label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "ax.set_title(f\"expansion rate: {EXPANSION_RATE}, settling frame: {SETTLING_FRAME}\")\n",
    "ax.set_xlabel(\"Euclidean similarity\")\n",
    "ax.set_ylabel(\"Timewarping similarity\")\n",
    "ax.set_zlabel(\"Length ratio\")\n",
    "ax.scatter(pos_similarities[:,0], pos_similarities[:,1], pos_similarities[:,2], c=\"k\", label=\"Positive\")\n",
    "ax.scatter(neg_similarities[:,0], neg_similarities[:,1], neg_similarities[:,2], c=\"w\", edgecolors=\"k\", label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = np.concatenate([pos_similarities, neg_similarities])\n",
    "y_total = np.array([+1 for _ in range(len(pos_similarities))] + [-1 for _ in range(len(neg_similarities))])\n",
    "print(x_total.shape)\n",
    "print(y_total.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=0.2, stratify=y_total, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_2d = SVC(kernel=\"linear\")\n",
    "svm_linear_2d.fit(x_train[:, 0:2], y_train)\n",
    "print(\"SVM(linear) Accuracy:\", svm_linear_2d.score(x_test[:, 0:2], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_3d = SVC(kernel=\"linear\")\n",
    "svm_linear_3d.fit(x_train, y_train)\n",
    "print(\"SVM(linear) Accuracy:\", svm_linear_3d.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly3 = SVC(kernel=\"poly\", degree=3)\n",
    "svm_poly3.fit(x_train, y_train)\n",
    "print(\"SVM(poly_3) Accuracy:\", svm_poly3.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly5 = SVC(kernel=\"poly\", degree=5)\n",
    "svm_poly5.fit(x_train, y_train)\n",
    "print(\"SVM(poly_5) Accuracy:\", svm_poly5.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly7 = SVC(kernel=\"poly\", degree=7)\n",
    "svm_poly7.fit(x_train, y_train)\n",
    "print(\"SVM(poly_7) Accuracy:\", svm_poly7.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\")\n",
    "svm_rbf.fit(x_train, y_train)\n",
    "print(\"SVM(rbf) Accuracy:\", svm_rbf.score(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b941a73e39ad5b6d75c9de32d8349d9c37685575ffd58a15534490e6472e926"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tensorflow23_py36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
